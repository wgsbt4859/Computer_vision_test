{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e301185f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting azure-cognitiveservices-vision-computervision\n",
      "  Downloading azure_cognitiveservices_vision_computervision-0.9.0-py2.py3-none-any.whl (39 kB)\n",
      "Collecting msrest>=0.5.0\n",
      "  Downloading msrest-0.7.1-py3-none-any.whl (85 kB)\n",
      "Collecting azure-common~=1.1\n",
      "  Downloading azure_common-1.1.28-py2.py3-none-any.whl (14 kB)\n",
      "Collecting azure-core>=1.24.0\n",
      "  Downloading azure_core-1.24.2-py3-none-any.whl (178 kB)\n",
      "Collecting isodate>=0.6.0\n",
      "  Downloading isodate-0.6.1-py2.py3-none-any.whl (41 kB)\n",
      "Collecting requests-oauthlib>=0.5.0\n",
      "  Downloading requests_oauthlib-1.3.1-py2.py3-none-any.whl (23 kB)\n",
      "Requirement already satisfied: requests~=2.16 in c:\\users\\wg_95\\anaconda3\\lib\\site-packages (from msrest>=0.5.0->azure-cognitiveservices-vision-computervision) (2.27.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\wg_95\\anaconda3\\lib\\site-packages (from msrest>=0.5.0->azure-cognitiveservices-vision-computervision) (2021.10.8)\n",
      "Requirement already satisfied: six>=1.11.0 in c:\\users\\wg_95\\anaconda3\\lib\\site-packages (from azure-core>=1.24.0->msrest>=0.5.0->azure-cognitiveservices-vision-computervision) (1.16.0)\n",
      "Requirement already satisfied: typing-extensions>=4.0.1 in c:\\users\\wg_95\\anaconda3\\lib\\site-packages (from azure-core>=1.24.0->msrest>=0.5.0->azure-cognitiveservices-vision-computervision) (4.1.1)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\wg_95\\anaconda3\\lib\\site-packages (from requests~=2.16->msrest>=0.5.0->azure-cognitiveservices-vision-computervision) (1.26.9)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in c:\\users\\wg_95\\anaconda3\\lib\\site-packages (from requests~=2.16->msrest>=0.5.0->azure-cognitiveservices-vision-computervision) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\wg_95\\anaconda3\\lib\\site-packages (from requests~=2.16->msrest>=0.5.0->azure-cognitiveservices-vision-computervision) (3.3)\n",
      "Collecting oauthlib>=3.0.0\n",
      "  Downloading oauthlib-3.2.0-py3-none-any.whl (151 kB)\n",
      "Installing collected packages: oauthlib, requests-oauthlib, isodate, azure-core, msrest, azure-common, azure-cognitiveservices-vision-computervision\n",
      "Successfully installed azure-cognitiveservices-vision-computervision-0.9.0 azure-common-1.1.28 azure-core-1.24.2 isodate-0.6.1 msrest-0.7.1 oauthlib-3.2.0 requests-oauthlib-1.3.1\n"
     ]
    }
   ],
   "source": [
    "!pip install --upgrade azure-cognitiveservices-vision-computervision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4322af57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pillow in c:\\users\\wg_95\\anaconda3\\lib\\site-packages (9.0.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install pillow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c5ed1b56",
   "metadata": {},
   "outputs": [],
   "source": [
    "from azure.cognitiveservices.vision.computervision import ComputerVisionClient\n",
    "from azure.cognitiveservices.vision.computervision.models import OperationStatusCodes\n",
    "from azure.cognitiveservices.vision.computervision.models import VisualFeatureTypes\n",
    "from msrest.authentication import CognitiveServicesCredentials\n",
    "\n",
    "from array import array\n",
    "import os\n",
    "from PIL import Image\n",
    "import sys\n",
    "import time\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "03c01396",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"secret.json\") as f:\n",
    "    secret = json.load(f)\n",
    "\n",
    "KEY = secret[\"KEY\"]\n",
    "ENDPOINT = secret[\"ENDPOINT\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c3650eb2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nEND - Authenticate\\n'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "Authenticate\n",
    "Authenticates your credentials and creates a client.\n",
    "'''\n",
    "computervision_client = ComputerVisionClient(ENDPOINT, CognitiveServicesCredentials(KEY))\n",
    "\n",
    "'''\n",
    "END - Authenticate\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f8dd18a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===== Tag an image - remote =====\n",
      "Tags in the remote image: \n",
      "'outdoor' with confidence 99.00%\n",
      "'building' with confidence 98.81%\n",
      "'sky' with confidence 98.21%\n",
      "'stadium' with confidence 98.17%\n",
      "'ancient rome' with confidence 96.16%\n",
      "'ruins' with confidence 95.04%\n",
      "'amphitheatre' with confidence 93.99%\n",
      "'ancient roman architecture' with confidence 92.65%\n",
      "'historic site' with confidence 89.55%\n",
      "'ancient history' with confidence 89.54%\n",
      "'history' with confidence 86.72%\n",
      "'archaeological site' with confidence 84.41%\n",
      "'travel' with confidence 65.85%\n",
      "'large' with confidence 61.02%\n",
      "'city' with confidence 56.57%\n",
      "\n",
      "End of Computer Vision quickstart.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "'''\n",
    "Quickstart variables\n",
    "These variables are shared by several examples\n",
    "'''\n",
    "# Images used for the examples: Describe an image, Categorize an image, Tag an image, \n",
    "# Detect faces, Detect adult or racy content, Detect the color scheme, \n",
    "# Detect domain-specific content, Detect image types, Detect objects\n",
    "#images_folder = os.path.join (os.path.dirname(os.path.abspath(__file__)), \"images\")\n",
    "\n",
    "remote_image_url = \"https://raw.githubusercontent.com/Azure-Samples/cognitive-services-sample-data-files/master/ComputerVision/Images/landmark.jpg\"\n",
    "'''\n",
    "END - Quickstart variables\n",
    "'''\n",
    "'''\n",
    "Tag an Image - remote\n",
    "This example returns a tag (key word) for each thing in the image.\n",
    "'''\n",
    "print(\"===== Tag an image - remote =====\")\n",
    "# Call API with remote image\n",
    "tags_result_remote = computervision_client.tag_image(remote_image_url )\n",
    "\n",
    "# Print results with confidence score\n",
    "print(\"Tags in the remote image: \")\n",
    "if (len(tags_result_remote.tags) == 0):\n",
    "    print(\"No tags detected.\")\n",
    "else:\n",
    "    for tag in tags_result_remote.tags:\n",
    "        print(\"'{}' with confidence {:.2f}%\".format(tag.name, tag.confidence * 100))\n",
    "print()\n",
    "'''\n",
    "END - Tag an Image - remote\n",
    "'''\n",
    "print(\"End of Computer Vision quickstart.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4645b00d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tags in the remote image: \n",
      "'a city with tall buildings' with confidence 48.47%\n",
      "\n",
      "End of Computer Vision quickstart.\n"
     ]
    }
   ],
   "source": [
    "description_results = computervision_client.describe_image(\"https://docs.microsoft.com/ja-jp/azure/cognitive-services/computer-vision/images/bw_buildings.png\")\n",
    "\n",
    "# Print results with confidence score\n",
    "print(\"Tags in the remote image: \")\n",
    "if (len(description_results.captions) == 0):\n",
    "    print(\"No description detected.\")\n",
    "else:\n",
    "    for caption in description_results.captions:\n",
    "        print(\"'{}' with confidence {:.2f}%\".format(caption.text, caption.confidence * 100))\n",
    "print()\n",
    "print(\"End of Computer Vision quickstart.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb973df6",
   "metadata": {},
   "source": [
    "## 画像カテゴリの取得"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "18f8b7af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===== Tag an image - remote =====\n",
      "\n",
      "Categories from remote image: \n",
      "'building_' with confidence 31.64%\n",
      "'others_' with confidence 0.39%\n",
      "'outdoor_' with confidence 3.91%\n",
      "\n"
     ]
    }
   ],
   "source": [
    "remote_image_url = \"https://raw.githubusercontent.com/Azure-Samples/cognitive-services-sample-data-files/master/ComputerVision/Images/landmark.jpg\"\n",
    "\n",
    "print(\"===== Tag an image - remote =====\")\n",
    "\n",
    "print()\n",
    "\n",
    "remote_image_features = [\"Categories\"]\n",
    "categorize_results = computervision_client.analyze_image(remote_image_url, remote_image_features)\n",
    "\n",
    "\n",
    "print(\"Categories from remote image: \")\n",
    "if (len(categorize_results.categories) == 0):\n",
    "    print(\"No categories detected.\")\n",
    "else:\n",
    "    for category in categorize_results.categories:\n",
    "        print(\"'{}' with confidence {:.2f}%\".format(category.name, category.score * 100))\n",
    "\n",
    "print()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e418d84e",
   "metadata": {},
   "source": [
    "## 画像へのタグ付け"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "236fa8c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===== Tag an image - remote =====\n",
      "\n",
      "Categories from remote image: \n",
      "'outdoor' with confidence 99.00%\n",
      "'building' with confidence 98.81%\n",
      "'sky' with confidence 98.21%\n",
      "'stadium' with confidence 98.17%\n",
      "'ancient rome' with confidence 96.16%\n",
      "'ruins' with confidence 95.04%\n",
      "'amphitheatre' with confidence 93.99%\n",
      "'ancient roman architecture' with confidence 92.65%\n",
      "'historic site' with confidence 89.55%\n",
      "'ancient history' with confidence 89.54%\n",
      "'history' with confidence 86.72%\n",
      "'archaeological site' with confidence 84.41%\n",
      "'travel' with confidence 65.85%\n",
      "'large' with confidence 61.02%\n",
      "'city' with confidence 56.57%\n",
      "\n"
     ]
    }
   ],
   "source": [
    "remote_image_url = \"https://raw.githubusercontent.com/Azure-Samples/cognitive-services-sample-data-files/master/ComputerVision/Images/landmark.jpg\"\n",
    "\n",
    "print(\"===== Tag an image - remote =====\")\n",
    "\n",
    "print()\n",
    "\n",
    "remote_image_features = [\"Tags\"]\n",
    "categorize_results = computervision_client.analyze_image(remote_image_url, remote_image_features)\n",
    "\n",
    "\n",
    "print(\"Categories from remote image: \")\n",
    "if (len(categorize_results.tags) == 0):\n",
    "    print(\"No categories detected.\")\n",
    "else:\n",
    "    for tag in categorize_results.tags:\n",
    "        print(\"'{}' with confidence {:.2f}%\".format(tag.name, tag.confidence * 100))\n",
    "\n",
    "print()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fb5dd0f",
   "metadata": {},
   "source": [
    "## オブジェクトの検出"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "9f71da84",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===== Tag an image - remote =====\n",
      "\n",
      "Categories from remote image: \n",
      "'kitchen appliance' with confidence 50.10% located at 730 865 66 151\n",
      "'computer keyboard' with confidence 51.00% located at 523 708 377 423\n",
      "'Laptop' with confidence 85.00% located at 471 760 218 444\n",
      "'person' with confidence 85.50% located at 654 1238 0 473\n",
      "\n"
     ]
    }
   ],
   "source": [
    "remote_image_url = \"https://docs.microsoft.com/ja-jp/azure/cognitive-services/computer-vision/images/windows-kitchen.jpg\"\n",
    "\n",
    "print(\"===== Tag an image - remote =====\")\n",
    "\n",
    "print()\n",
    "\n",
    "detect_objects_results = computervision_client.detect_objects(remote_image_url)\n",
    "\n",
    "\n",
    "print(\"Categories from remote image: \")\n",
    "if (len(detect_objects_results.objects) == 0):\n",
    "    print(\"No objects detected.\")\n",
    "else:\n",
    "    for detect_object in detect_objects_results.objects:\n",
    "        print(\"'{}' with confidence {:.2f}% located at {} {} {} {}\".format(detect_object.object_property, \\\n",
    "                                                                           detect_object.confidence * 100, \\\n",
    "                                                                           detect_object.rectangle.x, \\\n",
    "                                                                           detect_object.rectangle.x + detect_object.rectangle.w, \\\n",
    "                                                                           detect_object.rectangle.y, \\\n",
    "                                                                           detect_object.rectangle.y + detect_object.rectangle.h))\n",
    "\n",
    "print()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "642389c6",
   "metadata": {},
   "source": [
    "## ローカルファイルに対応させる"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c23fe277-29e8-45ab-a40d-0e5889ed595f",
   "metadata": {},
   "source": [
    "### ローカルファイル　オブジェクトの検出"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "6ee0a5b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===== Describe an Image - local =====\n",
      "{'additional_properties': {}, 'rectangle': <azure.cognitiveservices.vision.computervision.models._models_py3.BoundingRect object at 0x0000023127550430>, 'object_property': 'beverage', 'confidence': 0.666, 'parent': None}\n",
      "Categories from local image: \n",
      "'beverage' with confidence 66.60% located at 879 1201 262 773\n",
      "'Food' with confidence 80.90% located at 426 1085 835 1271\n"
     ]
    }
   ],
   "source": [
    "print(\"===== Describe an Image - local =====\")\n",
    "\n",
    "local_image_path = \"sample01.jpg\"\n",
    "local_image = open(local_image_path, \"rb\")\n",
    "\n",
    "#description_result = computervision_client.describe_image_in_stream(local_image)\n",
    "\n",
    "detect_objects_results = computervision_client.detect_objects_in_stream(local_image)\n",
    "\n",
    "#print(detect_objects_results.objects[0])\n",
    "\n",
    "print(\"Categories from local image: \")\n",
    "if (len(detect_objects_results.objects) == 0):\n",
    "    print(\"No objects detected.\")\n",
    "else:\n",
    "    for detect_object in detect_objects_results.objects:\n",
    "        print(\"'{}' with confidence {:.2f}% located at {} {} {} {}\".format(detect_object.object_property, \\\n",
    "                                                                           detect_object.confidence * 100, \\\n",
    "                                                                           detect_object.rectangle.x, \\\n",
    "                                                                           detect_object.rectangle.x + detect_object.rectangle.w, \\\n",
    "                                                                           detect_object.rectangle.y, \\\n",
    "                                                                           detect_object.rectangle.y + detect_object.rectangle.h))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ac4be14-8439-48dc-a51e-cece989d1380",
   "metadata": {},
   "source": [
    "### ローカルファイル　タグ付け"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "70c01a70-f9c3-4fdd-9eb5-31485b9cd1e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_tags(filepath):\n",
    "    local_image = open(filepath, \"rb\")\n",
    "\n",
    "    image_features = [\"Tags\"]\n",
    "    tag_results = computervision_client.analyze_image_in_stream(local_image, image_features) #_instreamを忘れないようにする！\n",
    "\n",
    "    tags = tag_results.tags\n",
    "    tags_name=[]\n",
    "\n",
    "    for tag in tags:\n",
    "        tags_name.append(tag.name)\n",
    "    return tags_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f40e3c53-48f6-4220-90ff-e008c83f5af3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['tableware',\n",
       " 'food',\n",
       " 'baked goods',\n",
       " 'plate',\n",
       " 'drink',\n",
       " 'coffee cup',\n",
       " 'dishware',\n",
       " 'saucer',\n",
       " 'snack',\n",
       " 'serveware',\n",
       " 'meal',\n",
       " 'mug',\n",
       " 'tea',\n",
       " 'fast food',\n",
       " 'breakfast',\n",
       " 'fork',\n",
       " 'kitchen utensil',\n",
       " 'dish',\n",
       " 'brunch',\n",
       " 'platter',\n",
       " 'dessert',\n",
       " 'cup',\n",
       " 'coffee',\n",
       " 'indoor',\n",
       " 'sitting',\n",
       " 'table']"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "local_image_path = \"sample01.jpg\"\n",
    "\n",
    "get_tags(local_image_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "7d11b19d-3468-402b-bf28-3151a546da94",
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_objects(filepath):\n",
    "\n",
    "    local_image = open(filepath, \"rb\")\n",
    "\n",
    "    detect_objects_results = computervision_client.detect_objects_in_stream(local_image)\n",
    "\n",
    "    objects = detect_objects_results.objects\n",
    "\n",
    "    return objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d358287a-1f82-4928-b84d-4e7c27779101",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<azure.cognitiveservices.vision.computervision.models._models_py3.DetectedObject at 0x23127554100>,\n",
       " <azure.cognitiveservices.vision.computervision.models._models_py3.DetectedObject at 0x23127554340>]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "local_image_path = \"sample01.jpg\"\n",
    "\n",
    "detect_objects(local_image_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "563a34e3-5841-4b5f-895b-c6a9be8fa005",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "8148c50a2d120338c2be287f06ef3744e8f308d60b93d433dcbf8c3ac89a6dfc"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
